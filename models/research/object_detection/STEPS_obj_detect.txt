BASIC REQIREMENTS STEPS:										log update:-     29-01-2020
------------------------------------------

1. INSTALL ANACONDA AND CREATE A VIRTUAL ENVIRONMENT "VENV" TO INSTALL THE LIBRARY FILES.
	In mycase 'tensorflow1'(inside bracket) will be my "virtualenvironment"
   
   	1.1:The required librarys are written in "requirements.txt". To install all the librarys at once run the following command.
		
		"  pip install -r requirements.txt "

2.Unzip the package files in the virtual environment directory.
3.The steps preceeded with the  "####	" are not necessary required as the zip file allready contains the pretrained models and inference graph.
	3.1 make sure check the mapped files are according to the destination. 
		the mentioned bellow files are placed as in the zip file.
		
		1. "labelmap.pbtxt" ---("\object detection\training\labelmap.pbtxt")
		2. "test.record" ---("\object detection\test.record")
		3."train.record" ---("\object detection\train.record")

***** these files should be matched with thee directory in the input of Faster R_CNN algorithm.*****
***** \object detection\training\faster_rcnn_inception_v2_pets.config  **** check the inputs of the config files as on the local system once the directorys are changed 	
4.cross check all the files are present and the inputs are mappped accordingly in the scripts.
5. from environment type the command
	" IDLE " ----displays the python idle from the virtual environment
	click open 
	select "Object_detection_webcam.py" 
	click "f5" or run the script.
	the webcam\camera will opened and it will detect the "TRAINED OBJECTS"

TO CHECK THE TENSORFLOW INSTALLATION:-
----------------------------------------------------------------------
 	TO CHECK THE TENSORFLOW INSTALLATION RUN THE "object_detection_tutorial.ipynb" file. make sure u installed jupyter notebook.
		"  jupyter notebook object_detection_tutorial.ipynb"
	this shold open the notebook on the default browser.
	just simple click run on the each modules.and make sure no errors are thrown.
	if the errors are thrown **good luck**!

THE BELLOW STEPS AND COMMANDS ARE FOR THE FRESH START:-
--------------------------------------------------------------------------------------------------
		```SET THE LIBRARY DIRECTORYS TO THE ENVIRONMENT VARIABLES TEMPROARILY```
		---------------------------------------------------------------------------------------------------------------------------------
####	(tensorflow1) C:\> set PYTHONPATH=C:\tensorflowone\models;C:\tensorflowone\models\research;C:\tensorflowone\models\research\slim

		``` CHANGE DIRECTORY```
		----------------------------------------
####	(tensorflow1) C:\> cd C:\tensorflow1\models\research

		``` TO COMPLE ALL THE ".proto" FILES AND CREATES THE ".pb2" FILES
		-------------------------------------------------------------------------------------------------------
####	protoc --python_out=. .\object_detection\protos\anchor_generator.proto .\object_detection\protos\argmax_matcher.proto .\object_detection\protos\bipartite_matcher.proto .\object_detection\protos\box_coder.proto .\object_detection\protos\box_predictor.proto .\object_detection\protos\eval.proto .\object_detection\protos\faster_rcnn.proto .\object_detection\protos\faster_rcnn_box_coder.proto .\object_detection\protos\grid_anchor_generator.proto .\object_detection\protos\hyperparams.proto .\object_detection\protos\image_resizer.proto .\object_detection\protos\input_reader.proto .\object_detection\protos\losses.proto .\object_detection\protos\matcher.proto .\object_detection\protos\mean_stddev_box_coder.proto .\object_detection\protos\model.proto .\object_detection\protos\optimizer.proto .\object_detection\protos\pipeline.proto .\object_detection\protos\post_processing.proto .\object_detection\protos\preprocessor.proto .\object_detection\protos\region_similarity_calculator.proto .\object_detection\protos\squar####	e_box_coder.proto .\object_detection\protos\ssd.proto .\object_detection\protos\ssd_anchor_generator.proto .\object_detection\protos\string_int_label_map.proto .\object_detection\protos\train.proto .\object_detection\protos\keypoint_box_coder.proto .\object_detection\protos\multiscale_anchor_generator.proto .\object_detection\protos\graph_rewriter.proto .\object_detection\protos\calibration.proto .\object_detection\protos\flexible_grid_anchor_generator.proto

		```SETPU BUILD & INSTALL```
		--------------------------------------------
####	(tensorflow1) C:\tensorflow1\models\research> python setup.py build
####	(tensorflow1) C:\tensorflow1\models\research> python setup.py install

		``` CONVERT XML TO .CSV FILE```
		-------------------------------------------------
####	(tensorflow1) C:\tensorflow1\models\research\object_detection> python xml_to_csv.py

		```CONVERT .CSV FILES TO TEST AND TRAIN. RECORD FILES```
		------------------------------------------------------------------------------------------
####	python generate_tfrecord.py --csv_input=images\train_labels.csv --image_dir=images\train --output_path=train.record
####	python generate_tfrecord.py --csv_input=images\test_labels.csv --image_dir=images\test --output_path=test.record

		```TRAIN RECORD FILES USING FASTER RCNN AND CREATE MODELS```
		-------------------------------------------------------------------------------------------------------
####	python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config

		```TO LOOKUP THE TRAINING LOGS AND INFERENCE GRAPHS```
		-----------------------------------------------------------------------------------------------
####	(tensorflow1) C:\tensorflow1\models\research\object_detection>tensorboard --logdir=training

		``` TO EXPORT INFERENCE GRAPH FROM THE TRAINED MODELS``` 
			***replace "XXXX" with the no. of trained models***
		-----------------------------------------------------------------------------------------------------
####	python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_pets.config --trained_checkpoint_prefix training/model.ckpt-XXXX --output_directory inference_graph

	
